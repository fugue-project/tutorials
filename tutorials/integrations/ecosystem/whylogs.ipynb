{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whylogs\n",
    "\n",
    "Have questions? Chat with us on Github or Slack:\n",
    "\n",
    "[![Homepage](https://img.shields.io/badge/fugue-source--code-red?logo=github)](https://github.com/fugue-project/fugue)\n",
    "[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](http://slack.fugue.ai)\n",
    "\n",
    "## Installation\n",
    "\n",
    "To use whylogs with Fugue, use install both whylogs with the Fugue extra, and fugue with whatever backend you plan to use. For example, to run on Spark, the command would be:\n",
    "\n",
    "`pip install 'whylogs[fugue]' 'fugue[spark]'`\n",
    "\n",
    "For Dask and Ray, just replace the Spark part of the installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we construct a dataset that we will use for profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = 100\n",
    "np.random.seed(0)\n",
    "tdf = pd.DataFrame(\n",
    "    dict(\n",
    "        a=np.random.choice([1, 2, 3], n),\n",
    "        b=np.random.choice([\"a\", \"b\"], n),\n",
    "        c=np.random.random(n),\n",
    "        d=np.random.choice([\"xy\", \"z\"], n),\n",
    "    )\n",
    ")\n",
    "tdf.to_parquet(\"/tmp/test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling using Whylogs + Fugue\n",
    "\n",
    "The simplest way to use profile is equivalent to use `why.log(df).view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardinality/est</th>\n",
       "      <th>cardinality/lower_1</th>\n",
       "      <th>cardinality/upper_1</th>\n",
       "      <th>counts/inf</th>\n",
       "      <th>counts/n</th>\n",
       "      <th>counts/nan</th>\n",
       "      <th>counts/null</th>\n",
       "      <th>distribution/max</th>\n",
       "      <th>distribution/mean</th>\n",
       "      <th>distribution/median</th>\n",
       "      <th>...</th>\n",
       "      <th>frequent_items/frequent_strings</th>\n",
       "      <th>ints/max</th>\n",
       "      <th>ints/min</th>\n",
       "      <th>type</th>\n",
       "      <th>types/boolean</th>\n",
       "      <th>types/fractional</th>\n",
       "      <th>types/integral</th>\n",
       "      <th>types/object</th>\n",
       "      <th>types/string</th>\n",
       "      <th>types/tensor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000150</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>[FrequentItem(value='1', est=39, upper=39, low...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[FrequentItem(value='a', est=57, upper=57, low...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>100.000025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.005018</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992396</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[FrequentItem(value='xy', est=53, upper=53, lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cardinality/est  cardinality/lower_1  cardinality/upper_1  counts/inf  \\\n",
       "column                                                                          \n",
       "a              3.000000                  3.0             3.000150           0   \n",
       "b              2.000000                  2.0             2.000100           0   \n",
       "c            100.000025                100.0           100.005018           0   \n",
       "d              2.000000                  2.0             2.000100           0   \n",
       "\n",
       "        counts/n  counts/nan  counts/null  distribution/max  \\\n",
       "column                                                        \n",
       "a            100           0            0          3.000000   \n",
       "b            100           0            0               NaN   \n",
       "c            100           0            0          0.992396   \n",
       "d            100           0            0               NaN   \n",
       "\n",
       "        distribution/mean  distribution/median  ...  \\\n",
       "column                                          ...   \n",
       "a                1.880000             2.000000  ...   \n",
       "b                0.000000                  NaN  ...   \n",
       "c                0.499929             0.487838  ...   \n",
       "d                0.000000                  NaN  ...   \n",
       "\n",
       "                          frequent_items/frequent_strings  ints/max  ints/min  \\\n",
       "column                                                                          \n",
       "a       [FrequentItem(value='1', est=39, upper=39, low...       3.0       1.0   \n",
       "b       [FrequentItem(value='a', est=57, upper=57, low...       NaN       NaN   \n",
       "c                                                     NaN       NaN       NaN   \n",
       "d       [FrequentItem(value='xy', est=53, upper=53, lo...       NaN       NaN   \n",
       "\n",
       "                      type  types/boolean  types/fractional  types/integral  \\\n",
       "column                                                                        \n",
       "a       SummaryType.COLUMN              0                 0             100   \n",
       "b       SummaryType.COLUMN              0                 0               0   \n",
       "c       SummaryType.COLUMN              0               100               0   \n",
       "d       SummaryType.COLUMN              0                 0               0   \n",
       "\n",
       "        types/object  types/string  types/tensor  \n",
       "column                                            \n",
       "a                  0             0             0  \n",
       "b                  0           100             0  \n",
       "c                  0             0             0  \n",
       "d                  0           100             0  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from whylogs.api.fugue import fugue_profile\n",
    "\n",
    "fugue_profile(tdf).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the specific columns to be used for profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardinality/est</th>\n",
       "      <th>cardinality/lower_1</th>\n",
       "      <th>cardinality/upper_1</th>\n",
       "      <th>counts/inf</th>\n",
       "      <th>counts/n</th>\n",
       "      <th>counts/nan</th>\n",
       "      <th>counts/null</th>\n",
       "      <th>distribution/max</th>\n",
       "      <th>distribution/mean</th>\n",
       "      <th>distribution/median</th>\n",
       "      <th>...</th>\n",
       "      <th>distribution/q_99</th>\n",
       "      <th>distribution/stddev</th>\n",
       "      <th>type</th>\n",
       "      <th>types/boolean</th>\n",
       "      <th>types/fractional</th>\n",
       "      <th>types/integral</th>\n",
       "      <th>types/object</th>\n",
       "      <th>types/string</th>\n",
       "      <th>types/tensor</th>\n",
       "      <th>frequent_items/frequent_strings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>100.000025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.005018</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992396</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992396</td>\n",
       "      <td>0.294085</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>[FrequentItem(value='xy', est=53, upper=53, lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cardinality/est  cardinality/lower_1  cardinality/upper_1  counts/inf  \\\n",
       "column                                                                          \n",
       "c            100.000025                100.0           100.005018           0   \n",
       "d              2.000000                  2.0             2.000100           0   \n",
       "\n",
       "        counts/n  counts/nan  counts/null  distribution/max  \\\n",
       "column                                                        \n",
       "c            100           0            0          0.992396   \n",
       "d            100           0            0               NaN   \n",
       "\n",
       "        distribution/mean  distribution/median  ...  distribution/q_99  \\\n",
       "column                                          ...                      \n",
       "c                0.499929             0.487838  ...           0.992396   \n",
       "d                0.000000                  NaN  ...                NaN   \n",
       "\n",
       "        distribution/stddev                type  types/boolean  \\\n",
       "column                                                           \n",
       "c                  0.294085  SummaryType.COLUMN              0   \n",
       "d                  0.000000  SummaryType.COLUMN              0   \n",
       "\n",
       "        types/fractional  types/integral  types/object  types/string  \\\n",
       "column                                                                 \n",
       "c                    100               0             0             0   \n",
       "d                      0               0             0           100   \n",
       "\n",
       "        types/tensor                    frequent_items/frequent_strings  \n",
       "column                                                                   \n",
       "c                  0                                                NaN  \n",
       "d                  0  [FrequentItem(value='xy', est=53, upper=53, lo...  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fugue_profile(tdf, profile_cols=[\"c\",\"d\"]).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assuming we want to use Spark to profile the dataset distributedly and assuming this is how we get a `SparkSession`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/27 16:38:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<whylogs.core.view.dataset_profile_view.DatasetProfileView at 0x7fc3c1b14250>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fugue_profile(tdf, engine=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to profile a SparkDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(tdf)\n",
    "fugue_profile(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly profile a parquet file or a folder of parquet files locally or on the cloud (the file will be loaded distributedly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fugue_profile(\"/tmp/test.parquet\", engine=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling by Partition\n",
    "\n",
    "If we want to profile tdf grouped by columns a and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fugue_profile(tdf, partition={\"by\":[\"a\",\"b\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also control the output profile field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fugue_profile(tdf, partition={\"by\":[\"a\",\"b\"]}, profile_field=\"x\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whylogs import DatasetProfileView\n",
    "\n",
    "res.x.apply(DatasetProfileView.deserialize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fugue_profile(tdf, partition={\"by\":[\"a\",\"b\"]}, engine=spark, as_local=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also directly save the output to a file distributedly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fugue_profile(tdf, partition={\"by\":[\"a\",\"b\"]}, save_path=\"/tmp/output1.parquet\", engine=spark)\n",
    "fugue_profile(\"/tmp/test.parquet\", partition={\"by\":[\"a\",\"b\"]}, save_path=\"/tmp/output2.parquet\", engine=spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using fugue_profile in the Fugue API way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fugue.api as fa\n",
    "\n",
    "with fa.engine_context(spark):\n",
    "    df = fa.load(\"/tmp/test.parquet\")\n",
    "    res = fugue_profile(df, partition={\"by\":[\"a\",\"b\"]})\n",
    "    fa.save(res, \"/tmp/output2.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization in FugueSQL\n",
    "Whylogs profile visualization is a auto-registered extension in Fugue. The namespace is why and the extension name is viz.\n",
    "\n",
    "Here is how you use the extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whylogs.api.fugue.registry  # you don't really need to import this explicitly, the registration is automatic\n",
    "import fugue.api as fa\n",
    "\n",
    "fa.fugue_sql_flow(\"\"\"\n",
    "-- visualize a single dataframe's profile\n",
    "OUTPUT df USING why:viz\n",
    "-- compare profiles, must set reference and target\n",
    "OUTPUT target=df, reference=df USING why:viz\n",
    "\"\"\", df = tdf).run();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "Whether using Spark, Ray or Dask, setting the number of partitions with the `num` keyword to two times of the cluster CPUs will work very well.\n",
    "\n",
    "```python\n",
    "fugue_profile(..., partition={\"num\": 200}, engine=spark)\n",
    "```\n",
    "\n",
    "Setting the number if also possible even if there are logical groupings.\n",
    "\n",
    "```python\n",
    "fugue_profile(..., partition={\"by\":[\"a\",\"b\"], \"num\": 200}, engine=spark)\n",
    "```\n",
    "\n",
    "**Spark**\n",
    "\n",
    "It is also beneficial to enabled pandas UDF on Spark to get better performance. We need to follow [this instruction](https://spark.apache.org/docs/3.0.0/sql-pyspark-pandas-with-arrow.html#enabling-for-conversion-tofrom-pandas) to enable `spark.sql.execution.arrow.pyspark.enabled`.\n",
    "\n",
    "The convention in Spark is to `spark.shuffle.partitions` when starting the Spark cluster. An ideal number should be 2-4 times of the total CPUs.\n",
    "\n",
    "**Ray**\n",
    "\n",
    "If the input DataFrame is a local DataFrame such as a Pandas DataFrame, there is no parallelism enabled by default. So in Ray, it is always a good idea to be explicit about `num`.\n",
    "\n",
    "**Dask**\n",
    "\n",
    "If the input DataFrame is a local DataFrame such as pandas DataFrame, the default partitioning will be a small number representing the local CPUs. So in Dask, it is always a good idea to be explicit about `num`.\n",
    "\n",
    "When we profile a DataFrame with logical partitions, we should also be explicit on how many physical partitions to use:\n",
    "\n",
    "```python\n",
    "fugue_profile(..., partition={\"by\":[\"a\",\"b\"], \"num\": 200}, engine=dask_client)\n",
    "```\n",
    "\n",
    "## Accessing Distributed Platforms\n",
    "\n",
    "In Fugue, accessing distributed platforms can be very simple. For example with proper setups, to profile a large S3 folder using Databricks, Anyscale or Coiled will be as simple as:\n",
    "\n",
    "```python\n",
    "fugue_profile(\"s3://<path>\", engine=\"db:<databricks_cluster_id>\")\n",
    "fugue_profile(\"s3://<path>\", engine=\"<anyscale_cluster_uri>\")\n",
    "fugue_profile(\"s3://<path>\", engine=\"coiled:<coiled_cluster_id>\")\n",
    "```\n",
    "\n",
    "For details of each platform, please read the instructions for [Databricks](https://fugue-tutorials.readthedocs.io/tutorials/integrations/cloudproviders/databricks.html), [Anyscale](https://fugue-tutorials.readthedocs.io/tutorials/integrations/cloudproviders/anyscale.html) and [Coiled](https://fugue-tutorials.readthedocs.io/tutorials/integrations/cloudproviders/coiled.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fugue')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "9fcd6e71927f6b3e5f4fa4280b4e8e6a66aa8d4365bb61cf7ef4017620fc09b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
