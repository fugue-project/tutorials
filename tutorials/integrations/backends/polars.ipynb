{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fugue with Polars\n",
    "\n",
    "Have questions? Chat with us on Github or Slack:\n",
    "\n",
    "[![Homepage](https://img.shields.io/badge/fugue-source--code-red?logo=github)](https://github.com/fugue-project/fugue)\n",
    "[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](http://slack.fugue.ai)\n",
    "\n",
    "Polars is a Rust-based DataFrame library that supports multi-threaded and out-of-core operations. The performance of Polars is already very good on a local machine, so the focus of the Fugue-Polars integration is scaling out to a cluster. Fugue also has [FugueSQL](../../quick_look/ten_minutes_sql.ipynb) to run SQL on top of DataFrames, but it is a lower priority for Polars because of the existing [DuckDB](../../integrations/backends/duckdb.ipynb) integration that can be used pretty easily with Polars. Because both are based on Apache Arrow, they can be used together with zero-copy as will also be shown here.\n",
    "\n",
    "Here are the use cases for this scenario:\n",
    "\n",
    "* Using DuckDB and Polars together seamlessly.\n",
    "* Scale out polars code on top of a Spark, Dask, Ray cluster to speed up computation.\n",
    "* In some cases, combinations like using Spark to run Polars jobs can be faster than native Spark itself (more in this later).\n",
    "\n",
    "Note that for distributed computing operations, a big overhead comes from data transfer over the cluster. This means that even if the actual compute executes quickly, the transfer may make total execution time longer. Users need to test whether bring Polars code to a cluster will be worth it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we create a Polars DataFrame and a function named `diff()` to get the difference (note there is no group). The type annotation of `pl.DataFrame` in the function below is needed by Fugue to eventually bring the code to Spark, Dask, or Ray. Note that the `diff()` function should be applied per group, but we can handle it on the Fugue level later. The Polars function is meant to handle one group at a time. This concept will be more important when we start to use the distributed engines like Spark, Dask, and Ray.\n",
    "\n",
    "For those new to Fugue, the comment above the function is used by Fugue to bring functions to Spark, Dask, and Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>number</th><th>diff</th></tr><tr><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;A&quot;</td><td>10</td><td>null</td></tr><tr><td>&quot;A&quot;</td><td>20</td><td>10</td></tr><tr><td>&quot;A&quot;</td><td>30</td><td>10</td></tr><tr><td>&quot;B&quot;</td><td>15</td><td>-15</td></tr><tr><td>&quot;B&quot;</td><td>25</td><td>10</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────┬────────┬──────┐\n",
       "│ id  ┆ number ┆ diff │\n",
       "│ --- ┆ ---    ┆ ---  │\n",
       "│ str ┆ i64    ┆ i64  │\n",
       "╞═════╪════════╪══════╡\n",
       "│ A   ┆ 10     ┆ null │\n",
       "│ A   ┆ 20     ┆ 10   │\n",
       "│ A   ┆ 30     ┆ 10   │\n",
       "│ B   ┆ 15     ┆ -15  │\n",
       "│ B   ┆ 25     ┆ 10   │\n",
       "└─────┴────────┴──────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "data = {\"id\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n",
    "        \"number\": [10, 20, 30, 15, 25, 35, 20, 30, 40]}\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# schema: *, diff:float\n",
    "def diff(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns(pl.col(\"number\").diff().alias(\"diff\"))\n",
    "\n",
    "diff(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DuckDB and Polars through FugueSQL\n",
    "\n",
    "There is great synergy with [DuckDB]((https://duckdb.org/)) and Polars because they are both based on Apache Arrow, which allows them to be interoperable with zero copy. There is no performance degradation by using these tools together. DuckDB is used to perform the SQL operations, and Polars handled the Python transformations that may be more tedious to express in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue_jupyter import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id:str</th>\n",
       "      <th>number:long</th>\n",
       "      <th>diff:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>40</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: id:str,number:long,diff:float</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql duckdb\n",
    "SELECT *\n",
    "  FROM df\n",
    " WHERE id IN ('B', 'C')\n",
    "\n",
    "TRANSFORM PREPARTITION BY id USING diff \n",
    "PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to use it in a script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>number</th><th>diff</th></tr><tr><td>str</td><td>i64</td><td>f32</td></tr></thead><tbody><tr><td>&quot;B&quot;</td><td>15</td><td>null</td></tr><tr><td>&quot;B&quot;</td><td>25</td><td>10.0</td></tr><tr><td>&quot;B&quot;</td><td>35</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>20</td><td>null</td></tr><tr><td>&quot;C&quot;</td><td>30</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>40</td><td>10.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 3)\n",
       "┌─────┬────────┬──────┐\n",
       "│ id  ┆ number ┆ diff │\n",
       "│ --- ┆ ---    ┆ ---  │\n",
       "│ str ┆ i64    ┆ f32  │\n",
       "╞═════╪════════╪══════╡\n",
       "│ B   ┆ 15     ┆ null │\n",
       "│ B   ┆ 25     ┆ 10.0 │\n",
       "│ B   ┆ 35     ┆ 10.0 │\n",
       "│ C   ┆ 20     ┆ null │\n",
       "│ C   ┆ 30     ┆ 10.0 │\n",
       "│ C   ┆ 40     ┆ 10.0 │\n",
       "└─────┴────────┴──────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fugue.api as fa\n",
    "from fugue.api import fugue_sql\n",
    "\n",
    "res = fugue_sql(\"\"\"\n",
    "                SELECT *\n",
    "                FROM df\n",
    "                WHERE id IN ('B', 'C')\n",
    "\n",
    "                TRANSFORM PREPARTITION BY id USING diff \n",
    "                \"\"\", engine=\"duckdb\")\n",
    "\n",
    "# Bring it into Polars from Arrow if needed.\n",
    "pl.from_arrow(fa.as_arrow(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fa.as_arrow` will convert whatever the SQL output is to Arrow. If the output is already an Arrow table, nothing will happen. Still, it's good to be explicitl about the conversion. From there, Polars can read in with the `pl.from_arrow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Polars Code Distributedly\n",
    "\n",
    "Polars already has amazing support for streaming larger than RAM datasets. Still, there are use cases for combining Polars and distributed backends like Spark, Dask, and Ray.\n",
    "\n",
    "* Instead of vertically scaling compute, we can scale horizontally instead by adding machines to our cluster. This can be more cost effective if we only need more workers for some more expensive steps.\n",
    "* If operations take too long on a local machine, it might be worth it to use a cluster to accelerate it.\n",
    "\n",
    "We can bring it to Spark without much code change. For Dask and Ray, it will be similar. Check the [execution engine](../../beginner/execution_engine.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>number</th><th>diff</th></tr><tr><td>str</td><td>i64</td><td>f32</td></tr></thead><tbody><tr><td>&quot;B&quot;</td><td>15</td><td>null</td></tr><tr><td>&quot;B&quot;</td><td>25</td><td>10.0</td></tr><tr><td>&quot;B&quot;</td><td>35</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>20</td><td>null</td></tr><tr><td>&quot;C&quot;</td><td>30</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>40</td><td>10.0</td></tr><tr><td>&quot;A&quot;</td><td>10</td><td>null</td></tr><tr><td>&quot;A&quot;</td><td>20</td><td>10.0</td></tr><tr><td>&quot;A&quot;</td><td>30</td><td>10.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 3)\n",
       "┌─────┬────────┬──────┐\n",
       "│ id  ┆ number ┆ diff │\n",
       "│ --- ┆ ---    ┆ ---  │\n",
       "│ str ┆ i64    ┆ f32  │\n",
       "╞═════╪════════╪══════╡\n",
       "│ B   ┆ 15     ┆ null │\n",
       "│ B   ┆ 25     ┆ 10.0 │\n",
       "│ B   ┆ 35     ┆ 10.0 │\n",
       "│ C   ┆ 20     ┆ null │\n",
       "│ …   ┆ …      ┆ …    │\n",
       "│ C   ┆ 40     ┆ 10.0 │\n",
       "│ A   ┆ 10     ┆ null │\n",
       "│ A   ┆ 20     ┆ 10.0 │\n",
       "│ A   ┆ 30     ┆ 10.0 │\n",
       "└─────┴────────┴──────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fugue.api import transform\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Output is Spark DataFrame\n",
    "res = transform(df, diff, partition={\"by\": \"id\"}, engine=spark)\n",
    "\n",
    "pl.from_arrow(fa.as_arrow(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Performance\n",
    "\n",
    "As mentioned in the introduction, using Polars distributedly takes some tuning. This is true for distributed computing in general; if a local data processing with Pandas or Polars is good enough, there is no need to introduce distributed computing. Bringing data and code to the cluster can just introduce overhead and slow down the work.\n",
    "\n",
    "With that in mind, the best operations to scale to Spark will like be compute-bound operations that take long. For example, you have 10 groups of data and processing each group can take 30 mins, it may make sense to spin up a cluster of 10 machines and have each one process a group. But there is still an open question when it comes to partitioning. \n",
    "\n",
    "Take the scenario where we have 100 distinct groups to operate on and 10 machines. We can:\n",
    "\n",
    "1. Create 100 partitions with Spark and run 100 Polars jobs\n",
    "2. Create 10 partitions in Spark (each holding 10 groups), and then each Polars job handles 10 groups\n",
    "\n",
    "The Fugue team worked on benchmarks and found that the second scenario can actually be significantly faster. In some cases (like calculating the z-score per group), it can actually be faster than native Spark. Either way, the point of Fugue is not to necessarily optimize for speed, but to adjust to the grammar users want to use. \n",
    "\n",
    "Still, this exact scenario led Fugue to the concept of \"coarse partitioning\", where we have few but larger partitiong. It can be used with one line of code, but bear in mind we need to adjust the function. Note the time can be inaccurate on a local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>number</th><th>diff</th></tr><tr><td>str</td><td>i64</td><td>f32</td></tr></thead><tbody><tr><td>&quot;B&quot;</td><td>15</td><td>null</td></tr><tr><td>&quot;B&quot;</td><td>25</td><td>10.0</td></tr><tr><td>&quot;B&quot;</td><td>35</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>20</td><td>null</td></tr><tr><td>&quot;C&quot;</td><td>30</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>40</td><td>10.0</td></tr><tr><td>&quot;A&quot;</td><td>10</td><td>null</td></tr><tr><td>&quot;A&quot;</td><td>20</td><td>10.0</td></tr><tr><td>&quot;A&quot;</td><td>30</td><td>10.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 3)\n",
       "┌─────┬────────┬──────┐\n",
       "│ id  ┆ number ┆ diff │\n",
       "│ --- ┆ ---    ┆ ---  │\n",
       "│ str ┆ i64    ┆ f32  │\n",
       "╞═════╪════════╪══════╡\n",
       "│ B   ┆ 15     ┆ null │\n",
       "│ B   ┆ 25     ┆ 10.0 │\n",
       "│ B   ┆ 35     ┆ 10.0 │\n",
       "│ C   ┆ 20     ┆ null │\n",
       "│ …   ┆ …      ┆ …    │\n",
       "│ C   ┆ 40     ┆ 10.0 │\n",
       "│ A   ┆ 10     ┆ null │\n",
       "│ A   ┆ 20     ┆ 10.0 │\n",
       "│ A   ┆ 30     ┆ 10.0 │\n",
       "└─────┴────────┴──────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# schema: *, diff:float\n",
    "def diff(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns(pl.col(\"number\").diff().over('id').alias(\"diff\"))\n",
    "\n",
    "res = transform(df, diff, partition={\"by\": \"id\", \"algo\": \"coarse\"}, engine=spark)\n",
    "\n",
    "pl.from_arrow(fa.as_arrow(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Input and Output Types\n",
    "\n",
    "To apply a function per group of data, we can use the `Iterable[pl.DataFrame]` input annotation and the `Iterator[pl.DataFrame]` output annotation. Note that the `min_per_group()` function below gets the `max()` value. This aggregation is done for each partition (or group).\n",
    "\n",
    "For this specific example, the logic can also be expressed in Polars, but for more complicated transformations on each logical group, this setup is an option to express the logic. It will also be scalable to Spark/Dask/Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Iterator\n",
    "\n",
    "# schema: *, c:int\n",
    "def min_per_group(dfs: Iterable[pl.DataFrame]) -> Iterator[pl.DataFrame]:\n",
    "    for df in dfs:\n",
    "        tdf = df.max().with_columns(pl.lit(1, pl.Int32()).alias(\"c\"))\n",
    "        yield tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  number  c\n",
       "0  A      30  1\n",
       "1  B      35  1\n",
       "2  C      40  1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(df, min_per_group, partition={\"by\": \"id\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fugue')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fcd6e71927f6b3e5f4fa4280b4e8e6a66aa8d4365bb61cf7ef4017620fc09b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
