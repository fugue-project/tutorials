{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fugue with Ibis\n",
    "\n",
    "The [Ibis project](https://ibis-project.org/docs/) tries to bridge the gap between local Python and [various datastore backends](https://ibis-project.org/docs/backends/index.html) including distributed systems such as Spark and Dask. The main idea is to create a pythonic interface to express SQL semantics, so the expression is agnostic to the backends.\n",
    "\n",
    "The design idea is very aligned with Fugue. But please notice there are a few key differences:\n",
    "\n",
    "* **Fugue supports both pythonic APIs and SQL**, and the choice should be determined by particular cases or users' preferences. On the other hand, Ibis focuses on the pythonic expression of SQL and perfects it.\n",
    "* **Fugue supports SQL and non-SQL semantics for data transformation.** Besides SQL, another important option is [Fugue Transform](introduction.html#fugue-transform). The Fugue transformers can wrap complicated Python/Pandas logic and apply them distributedly on dataframes. A typical example is distributed model inference, the inference part has to be done by Python, it can be easily achieved by a `transformer`, but the data preparation may be done nicely by SQL or Ibis.\n",
    "* **Fugue and Ibis are on different abstraction layers.** Ibis is nice to construct single SQL statements to accomplish single tasks. Even it involves multiple tables and multiple steps, its final step is either outputting one table or inserting one table into a database. On the other hand, `FugueWorkflow` is to orchestrate these tasks. For example, a workflow can read a table, do the first transformation and save to a file, then do the second transformation and print. Each transformation may be done using Ibis, but loading, saving and printing and the orchestration can be done by Fugue.\n",
    "\n",
    "This is also why Ibis can be a very nice option for Fugue users to build their pipelines. For people who prefer pythonic APIs, they can keep all the logic in Python with the help of Ibis. Although Fugue has its own functional API similar to Ibis, the programming interface of Ibis is really elegant. It usually helps users write less but more expressive code to achieve the same thing.\n",
    "\n",
    "## Hello World\n",
    "\n",
    "In this example, we try to achieve this SQL semantic:\n",
    "\n",
    "```sql\n",
    "SELECT a, a+1 AS b FROM\n",
    "    (SELECT a FROM tb1 UNION SELECT a FROM tb2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibis import BaseBackend, literal\n",
    "import ibis.expr.types as ir\n",
    "\n",
    "def ibis_func(backend:BaseBackend) -> ir.TableExpr:\n",
    "    tb1 = backend.table(\"tb1\")\n",
    "    tb2 = backend.table(\"tb2\")\n",
    "    tb3 = tb1.union(tb2)\n",
    "    return tb3.mutate(b=tb3.a+literal(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test with the pandas backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  0  1\n",
       "1  1  2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ibis\n",
    "import pandas as pd\n",
    "\n",
    "con = ibis.pandas.connect({\n",
    "    \"tb1\": pd.DataFrame([[0]], columns=[\"a\"]),\n",
    "    \"tb2\": pd.DataFrame([[1]], columns=[\"a\"])\n",
    "})\n",
    "ibis_func(con).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make this a part of Fugue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue import FugueWorkflow\n",
    "from fugue_ibis import run_ibis\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df1 = dag.df([[0]], \"a:long\")\n",
    "df2 = dag.df([[1]], \"a:long\")\n",
    "df3 = run_ibis(ibis_func, tb1=df1, tb2=df2)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run on Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:long|b:long\n",
      "------+------\n",
      "0     |1     \n",
      "1     |2     \n",
      "Total count: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run on Dask. This assumes Dask is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaskDataFrame\n",
      "a:long|b:long\n",
      "------+------\n",
      "0     |1     \n",
      "1     |2     \n",
      "Total count: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.run(\"dask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run on DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:long|b:long\n",
      "------+------\n",
      "0     |1     \n",
      "1     |2     \n",
      "Total count: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fugue_duckdb\n",
    "\n",
    "dag.run(\"duck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each different execution engine, Ibis will also run on the correspondent backend.\n",
    "\n",
    "## A deeper integration\n",
    "\n",
    "The above approach needs a function taking in an Ibis backend and returning a `TableExpr`. The following is another approach that simpler and more elegant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:long|b:long\n",
      "------+------\n",
      "0     |1     \n",
      "1     |2     \n",
      "Total count: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fugue_ibis import as_ibis, as_fugue\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "tb1 = as_ibis(dag.df([[0]], \"a:long\"))\n",
    "tb2 = as_ibis(dag.df([[1]], \"a:long\"))\n",
    "tb3 = tb1.union(tb2)\n",
    "df3 = as_fugue(tb3.mutate(b=tb3.a+literal(1)))\n",
    "df3.show()\n",
    "\n",
    "dag.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can treat `as_ibis` and `as_fugue` as class methods. This is more convenient to use, but it's a bit magical. This is achieved by adding these two methods using `setattr` to the correspondent classes. This patching-like design pattern is widely used by Ibis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:long|b:long\n",
      "------+------\n",
      "0     |1     \n",
      "1     |2     \n",
      "Total count: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fugue_ibis  # must import\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "tb1 = dag.df([[0]], \"a:long\").as_ibis()\n",
    "tb2 = dag.df([[1]], \"a:long\").as_ibis()\n",
    "tb3 = tb1.union(tb2)\n",
    "df3 = tb3.mutate(b=tb3.a+literal(1)).as_fugue()\n",
    "df3.show()\n",
    "\n",
    "dag.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By importing `fugue_ibis`, the two methods were automatically added.\n",
    "\n",
    "It's up to the users which way to go. The first approach (`run_ibis`) is the best to separate Ibis logic, as you can see, it is also great for unit testing. The second approach is elegant, but you will have to unit test the code with the logic before and after the conversions. The third approach is the most intuitive, but it's a bit magical.\n",
    "\n",
    "## Z-Score\n",
    "\n",
    "Now, let's consider a practical example. We want to use Fugue to compute z-score of a dataframe, partitioning should be an option. The reason to implement it on Fugue level is that the compute becomes scale agnostic and framework agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue import WorkflowDataFrame\n",
    "from fugue_ibis import as_ibis, as_fugue\n",
    "\n",
    "def z_score(df:WorkflowDataFrame, input_col:str, output_col:str) -> WorkflowDataFrame:\n",
    "    by = df.partition_spec.partition_by\n",
    "    idf = as_ibis(df)\n",
    "    col = idf[input_col]    \n",
    "    if len(by)==0:\n",
    "        return as_fugue(idf.mutate(**{output_col:(col - col.mean())/col.std()}))\n",
    "    agg = idf.group_by(by).aggregate(mean_=col.mean(), std_=col.std())\n",
    "    j = idf.inner_join(agg, by)[idf, ((idf[input_col]-agg.mean_)/agg.std_).name(output_col)]\n",
    "    return as_fugue(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "pdf = pd.DataFrame(dict(\n",
    "    a=np.random.choice([\"a\",\"b\"], 100),\n",
    "    b=np.random.choice([\"c\",\"d\"], 100),\n",
    "    c=np.random.rand(100),\n",
    "))\n",
    "\n",
    "pdf[\"expected1\"] = (pdf.c - pdf.c.mean())/pdf.c.std()\n",
    "pdf = pdf.groupby([\"a\", \"b\"]).apply(lambda tdf: tdf.assign(expected2=(tdf.c - tdf.c.mean())/tdf.c.std())).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the final code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:str|b:str|c:double     |expected1:double  |expected2:double  |z1:double    |z2:double   \n",
      "-----+-----+-------------+------------------+------------------+-------------+------------\n",
      "a    |c    |0.84640867247|1.144636809499835 |1.577770556350802 |1.14463680949|1.5777705563\n",
      "     |     |11278        |                  |                  |98345        |508022      \n",
      "a    |c    |0.69947927531|0.6163095213101546|1.0316513450169476|0.61630952131|1.0316513450\n",
      "     |     |75043        |                  |                  |01543        |169478      \n",
      "a    |c    |0.81379781970|1.0273750242983348|1.4565598691775665|1.02737502429|1.4565598691\n",
      "     |     |24772        |                  |                  |83344        |77567       \n",
      "a    |c    |0.39650574084|-0.473119748536303|-0.094465490044129|-0.4731197485|-0.094465490\n",
      "     |     |698464       |06                |49                |3630345      |0441295     \n",
      "a    |c    |0.58127287263|0.1912640955118427|0.5922921108698395|0.19126409551|0.5922921108\n",
      "     |     |58587        |9                 |                  |18424        |698396      \n",
      "a    |c    |0.29828232595|-0.826310542423581|-0.459550319315429|-0.8263105424|-0.459550319\n",
      "     |     |603077       |5                 |6                 |235819       |3154297     \n",
      "a    |c    |0.57432524884|0.1662818979021328|0.5664686140318282|0.16628189790|0.5664686140\n",
      "     |     |95788        |8                 |                  |21325        |318284      \n",
      "a    |c    |0.43141843543|-0.347581023054070|0.0353008712338056|-0.3475810230|0.0353008712\n",
      "     |     |397396       |96                |9                 |540714       |33805695    \n",
      "a    |c    |0.43586492526|-0.331592378438154|0.0518279486404278|-0.3315923784|0.0518279486\n",
      "     |     |56268        |5                 |1                 |3815487      |4042782     \n",
      "a    |c    |0.14944830465|-1.361486459469925|-1.012748793586346|-1.3614864594|-1.012748793\n",
      "     |     |799375       |9                 |2                 |699263       |5863462     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag = FugueWorkflow()\n",
    "df = z_score(dag.df(pdf), \"c\", \"z1\")\n",
    "df = z_score(df.partition_by(\"a\", \"b\"), \"c\", \"z2\")\n",
    "df.show()\n",
    "\n",
    "dag.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency issues\n",
    "\n",
    "Ibis as of 2.0.0 can have different behaviors on different backends. Here are some examples from the common discrepancies between pandas and SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:str|s:long\n",
      "-----+------\n",
      "a    |1     \n",
      "Total count: 1\n",
      "\n",
      "PandasDataFrame\n",
      "a:str|s:long\n",
      "-----+------\n",
      "a    |1     \n",
      "NULL |2     \n",
      "Total count: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas drops null keys on group (by default), SQL doesn't\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df = dag.df([[\"a\",1],[None,2]], \"a:str,b:int\").as_ibis()\n",
    "df.groupby([\"a\"]).aggregate(s=df.b.sum()).as_fugue().show()\n",
    "\n",
    "dag.run()\n",
    "dag.run(\"duckdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandasDataFrame\n",
      "a:str|b:int|c:int\n",
      "-----+-----+-----\n",
      "a    |1    |1    \n",
      "NULL |2    |2    \n",
      "Total count: 2\n",
      "\n",
      "PandasDataFrame\n",
      "a:str|b:int|c:int\n",
      "-----+-----+-----\n",
      "a    |1    |1    \n",
      "Total count: 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrames()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas joins on NULLs, SQL doesn't\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "df1 = dag.df([[\"a\",1],[None,2]], \"a:str,b:int\").as_ibis()\n",
    "df2 = dag.df([[\"a\",1],[None,2]], \"a:str,c:int\").as_ibis()\n",
    "df1.inner_join(df2, [\"a\"])[df1, df2.c].as_fugue().show()\n",
    "\n",
    "dag.run()\n",
    "dag.run(\"duckdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Ibis integration is experimental, we rely on Ibis to achieve consistent behaviors. If you have any Ibis specific question please also consider asking in [Ibis issues](https://github.com/ibis-project/ibis/issues)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
