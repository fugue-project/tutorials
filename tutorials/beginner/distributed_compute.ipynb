{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Distributed Compute\n",
    "\n",
    "This is a heart of Fugue. In the previous sections, we went over how to use Fugue in the form of extensions and basic data operations such as joins. In this section, we'll talk about how those Fugue extensions scale."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Partition and Presort\n",
    "\n",
    "One of the most fundamental distributed compute concepts is the partition. Our data is spread across several machines, and we often need to rearrange the way the data is spread across the machines. This is because of operations that need all of the related data in one place. For example, calculating the median value per group requires all of the data from the same group on one machine. Fugue allows users to control the paritioning scheme during execution.\n",
    "\n",
    "In the example below, `take` is an operation that extracts `n` number of rows. We apply take on each partition. We will have two partitions because `col1` is the partition key and it only has 2 values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from fugue import FugueWorkflow\n",
    "import pandas as pd \n",
    "\n",
    "data = pd.DataFrame({'col1':[1,1,1,2,2,2], 'col2':[1,4,5,7,4,2]})\n",
    "df2 = data.copy()\n",
    "\n",
    "with FugueWorkflow() as dag:\n",
    "    df = dag.df(df2)\n",
    "    df = df.partition(by=['col1'], presort=\"col2 desc\").take(1)\n",
    "    df.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PandasDataFrame\n",
      "col1:long|col2:long\n",
      "---------+---------\n",
      "2        |7        \n",
      "1        |5        \n",
      "Total count: 2\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also used `presort`. The presort key here was `col2 desc`, which means that the data is sorted in descending order after partitioning. This makes the `take` operation give us the max value. We'll go over one more example."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# schema: *, col2_diff:int\n",
    "def diff(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['col2_diff'] = df['col2'].diff(1)\n",
    "    return df\n",
    "\n",
    "df2 = data.copy()\n",
    "with FugueWorkflow() as dag:\n",
    "    df = dag.df(df2)\n",
    "    df = df.partition(by=['col1']).transform(diff)\n",
    "    df.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PandasDataFrame\n",
      "col1:long|col2:long|col2_diff:int\n",
      "---------+---------+-------------\n",
      "1        |1        |NULL         \n",
      "1        |4        |3            \n",
      "1        |5        |1            \n",
      "2        |7        |NULL         \n",
      "2        |4        |-3           \n",
      "2        |2        |-2           \n",
      "Total count: 6\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice there are 2 NULL values in the previous example. This is because the first element of the `diff` operation results in NULL. The reason we have 2 NULLs is because the `transformer` was applied once for each partition. The `partition-transform` semantics are very similar to the `pandas groupby-apply` semantics. There is a deeper dive into partitions in the advanced tutorial."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CoTransformer\n",
    "\n",
    "Last section, we skipped the `cotransformer` because it required knowledge about partitions. The `cotransformer` takes in multiple DataFrames that are **partitioned in the same way** and outputs one DataFrame. In order to use a `cotransformer`, the `zip` method has to be used first to join them by their common keys. There is also a `@cotransformer` decorator can be used to define the `cotransformer`, but it will still be invoked by the `zip-transform` syntax.\n",
    "\n",
    "In the example below, we will do a merge as-of operation on different groups of data. In order to align the data with events as they get distributed across the cluster, we will partition them in the same way."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'group': ([\"A\"] * 5 + [\"B\"] * 5),\n",
    "                     'year': [2015,2016,2017,2018,2019] * 2})\n",
    "\n",
    "events = pd.DataFrame({'group': [\"A\", \"A\", \"B\", \"B\"],\n",
    "                       'year': [2014, 2016, 2014, 2018],\n",
    "                       \"value\": [1, 2, 1, 2]})\n",
    "\n",
    "events.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  group  year  value\n",
       "0     A  2014      1\n",
       "1     A  2016      2\n",
       "2     B  2014      1\n",
       "3     B  2018      2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pandas `merge_asof` function requires that the `on` column is sorted. To do this, we apply a `partition` strategy on Fugue by group and presort by the year. By the time it arrives in the `cotransformer`, the dataframes are sorted and grouped."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from fugue import FugueWorkflow\n",
    "\n",
    "# schema: group:str,year:int,value:int\n",
    "def merge_asof(data:pd.DataFrame, events:pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.merge_asof(data, events, on=\"year\", by=\"group\")\n",
    "\n",
    "with FugueWorkflow() as dag:\n",
    "    data = dag.df(data)\n",
    "    events = dag.df(events)\n",
    "\n",
    "    data.zip(events, partition={\"by\": \"group\", \"presort\": \"year\"}).transform(merge_asof).show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PandasDataFrame\n",
      "group:str|year:int|value:int\n",
      "---------+--------+---------\n",
      "A        |2015    |1        \n",
      "A        |2016    |2        \n",
      "A        |2017    |2        \n",
      "A        |2018    |2        \n",
      "A        |2019    |2        \n",
      "B        |2015    |1        \n",
      "B        |2016    |1        \n",
      "B        |2017    |1        \n",
      "B        |2018    |2        \n",
      "B        |2019    |2        \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, the important part to note is each group uses the pandas `merge_asof` independently. This function is very flexible, allowing users to specify forward and backward merges along with a tolerance. This is tricky to implement well in Spark, but the `cotransformer` lets us do it easily.\n",
    "\n",
    "This operation was partitioned by the column `group` before the `cotransform` was applied. This was done through the `zip` command. `CoTransform` is a more advanced operation that may take some experience to get used to."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Persist and Broadcast\n",
    "\n",
    "Persist and broadcast are two other distributed compute concepts that Fugue has support for. Persist keeps a DataFrame in memory to avoid recomputation. Distributed compute frameworks often need an explicit `persist` call to know which DataFrames need to be kept, otherwise they tend to be calculated repeatedly.\n",
    "\n",
    "Broadcasting is making a smaller DataFrame available on all the workers of a cluster. Without `broadcast`, these small DataFrames would be repeatedly sent to workers whenever they are needed to perform an operation. Broadcasting caches them on the workers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with FugueWorkflow() as dag:\n",
    "    df = dag.df([[0,1],[1,2]],\"a:long,b:long\")\n",
    "    df.persist()\n",
    "    df.broadcast()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}