{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FugueSQL in 10 Minutes\n",
    "\n",
    "Have questions? Chat with us on Github or Slack:\n",
    "\n",
    "[![Homepage](https://img.shields.io/badge/fugue-source--code-red?logo=github)](https://github.com/fugue-project/fugue)\n",
    "[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](http://slack.fugue.ai)\n",
    "\n",
    "This is a short introduction of FugueSQL geared for new users. FugueSQL is the SQL interface for [Fugue](https://github.com/fugue-project/fugue). The Fugue project aims to make big data effortless by accelerating iteration speed and providing a simpler interface for users to utilize distributed computing engines.\n",
    "\n",
    "This tutorial only covers the SQL interface. For Python, check the [Fugue API in 10 minutes section](ten_minutes.ipynb). Note that this is just an overview of the features, not a full tutorial.\n",
    "\n",
    "FugueSQL is meant for SQL lovers who want to use their preferred grammar of choice on top of Pandas, Spark and Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "There are two things to install. First is FugueSQL (which is separate from Fugue). Install it with:\n",
    "\n",
    "```\n",
    "pip install fugue[sql]\n",
    "```\n",
    "\n",
    "FugueSQL has a notebook extension for both Jupyter Notebooks and JupyterLab. This extension provides syntax highlighting. To install the extension, use pip:\n",
    "\n",
    "```\n",
    "pip install fugue-jupyter\n",
    "```\n",
    "\n",
    "and then to register the startup script:\n",
    "\n",
    "```\n",
    "fugue-jupyter install startup\n",
    "```\n",
    "\n",
    "See [this documentation](https://github.com/fugue-project/fugue-jupyter) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you are using Jupyter lab and followed the installation instructions above, then the `%%fsql` cell magic is already registered by default. Otherwise, it can be used using the following command where `is_lab` indicates if you are using Jupyter Lab versus Classic Jupyter Notebooks. This `setup()` gives both the cell magic and the syntax highlighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\nrequire([\"codemirror/lib/codemirror\"]);\nfunction set(str) {\n    var obj = {}, words = str.split(\" \");\n    for (var i = 0; i < words.length; ++i) obj[words[i]] = true;\n    return obj;\n  }\nvar fugue_keywords = \"fill hash rand even presort persist broadcast params process output outtransform rowcount concurrency prepartition zip print title save append parquet csv json single checkpoint weak strong deterministic yield connect sample seed take sub callback dataframe file\";\nCodeMirror.defineMIME(\"text/x-fsql\", {\n    name: \"sql\",\n    keywords: set(fugue_keywords + \" add after all alter analyze and anti archive array as asc at between bucket buckets by cache cascade case cast change clear cluster clustered codegen collection column columns comment commit compact compactions compute concatenate cost create cross cube current current_date current_timestamp database databases data dbproperties defined delete delimited deny desc describe dfs directories distinct distribute drop else end escaped except exchange exists explain export extended external false fields fileformat first following for format formatted from full function functions global grant group grouping having if ignore import in index indexes inner inpath inputformat insert intersect interval into is items join keys last lateral lazy left like limit lines list load local location lock locks logical macro map minus msck natural no not null nulls of on optimize option options or order out outer outputformat over overwrite partition partitioned partitions percent preceding principals purge range recordreader recordwriter recover reduce refresh regexp rename repair replace reset restrict revoke right rlike role roles rollback rollup row rows schema schemas select semi separated serde serdeproperties set sets show skewed sort sorted start statistics stored stratify struct table tables tablesample tblproperties temp temporary terminated then to touch transaction transactions transform true truncate unarchive unbounded uncache union unlock unset use using values view when where window with\"),\n    builtin: set(\"date datetime tinyint smallint int bigint boolean float double string binary timestamp decimal array map struct uniontype delimited serde sequencefile textfile rcfile inputformat outputformat\"),\n    atoms: set(\"false true null\"),\n    operatorChars: /^[*\\/+\\-%<>!=~&|^]/,\n    dateSQL: set(\"time\"),\n    support: set(\"ODBCdotTable doubleQuote zerolessFloat\")\n  });\n\nCodeMirror.modeInfo.push( {\n            name: \"Fugue SQL\",\n            mime: \"text/x-fsql\",\n            mode: \"sql\"\n          } );\n\nrequire(['notebook/js/codecell'], function(codecell) {\n    codecell.CodeCell.options_default.highlight_modes['magic_text/x-fsql'] = {'reg':[/%%fsql/]} ;\n    Jupyter.notebook.events.on('kernel_ready.Kernel', function(){\n    Jupyter.notebook.get_cells().map(function(cell){\n        if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n    });\n  });\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fugue_notebook import setup\n",
    "\n",
    "setup(is_lab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard SQL Compatible\n",
    "\n",
    "FugueSQL is meant for SQL users to work with Python DataFrames (Pandas, Spark, and Dask). FugueSQL is parsed and then executed on the underlying engine. For example, FugueSQL with Spark is run on top of SparkSQL and PySpark. We'll see non-standard SQL commands later but for now, the important thing to note is that Fugue is compatible with standard SQL. \n",
    "\n",
    "First, we define two Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"col1\": [\"A\",\"A\",\"A\",\"B\",\"B\",\"B\"], \"col2\": [1,2,3,4,5,6]})\n",
    "df2 = pd.DataFrame({\"col1\": [\"A\", \"B\"], \"col3\": [1, 2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use them in a `%%fsql` cell as seen below. `PRINT` is a FugueSQL keyword to display the first few rows of the DataFrame. Everything else besides `PRINT` is standard SQL. By default, `%%fsql` will run on Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>col2:long</th>\n",
       "      <th>col3:long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: col1:str,col2:long,col3:long</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql\n",
    "   SELECT df.col1, df.col2, df2.col3\n",
    "     FROM df\n",
    "LEFT JOIN df2\n",
    "       ON df.col1 = df2.col1\n",
    "    WHERE df.col1 = \"A\"\n",
    "    PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FugueSQL DataFrame in Python\n",
    "\n",
    "FugueSQL can access DataFrames defined in Python. To use a DataFrame from a FugueSQL query, we need to use the `YIELD` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\":  [\"A\",\"A\",\"A\",\"B\",\"B\",\"B\"], \"col2\": [1,2,3,4,5,6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "SELECT *\n",
    "  FROM df\n",
    " YIELD DATAFRAME AS result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YIELD` will make the variable available in Python. It will be a `FugueDataFrame` where `.native` contains the underlying Pandas, Spark, or Dask DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fugue.dataframe.pandas_dataframe.PandasDataFrame'>\n",
      "  col1  col2\n",
      "0    A     1\n",
      "1    A     2\n",
      "2    A     3\n",
      "3    B     4\n",
      "4    B     5\n"
     ]
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(result.native.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Files\n",
    "\n",
    "In the previous cells, we relied on Python cells to load in the files and then bring them to FugueSQL. We can use FugueSQL to `LOAD` and `SAVE` the files directly. Parquet files are the most preferred method but CSVs and JSON are also supported. They just require some additional arguments. [See the LOAD documentation](https://fugue-tutorials.readthedocs.io/tutorials/fugue_sql/operators.html#load) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\": [\"A\",\"A\",\"A\",\"B\",\"B\",\"B\"], \"col2\": [1,2,3,4,5,6]})\n",
    "df2 = pd.DataFrame({\"col1\": [\"A\", \"B\"], \"col3\": [1, 2]})\n",
    "df.to_parquet(\"/tmp/df.parquet\")\n",
    "df2.to_parquet(\"/tmp/df2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "df = LOAD \"/tmp/df.parquet\"\n",
    "df2 = LOAD \"/tmp/df2.parquet\"\n",
    "\n",
    "new =  SELECT df.col1, df.col2, df2.col3\n",
    "         FROM df\n",
    "         LEFT JOIN df2\n",
    "           ON df.col1 = df2.col1 \n",
    "        WHERE df.col1 = \"A\"\n",
    "\n",
    "SAVE OVERWRITE \"/tmp/res.parquet\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Assignment\n",
    "\n",
    "As seen in the previous cell, Fugue simplifies SQL syntax by removing the need for common table expressions (CTEs). CTEs are still supported but FugueSQL users can assign tables to variables with the `=` sign. This reduces a significant amount of boilerplate code SQL practitioners have to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>normalized:double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: col1:str,normalized:double</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql\n",
    "df = LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "max_vals = SELECT col1, MAX(col2) AS max_val\n",
    "             FROM df\n",
    "         GROUP BY col1\n",
    "\n",
    "   SELECT df.col1, \n",
    "          df.col2 / max_vals.max_val AS normalized\n",
    "     FROM df\n",
    "     JOIN max_vals\n",
    "       ON df.col1 = max_vals.col1\n",
    "    PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymity (Optional)\n",
    "\n",
    "The boilerplate code the SQL introduces can be reduced further by using a FugueSQL featured called anonymity. If no `FROM` clause is used, the last table will be pulled. This way, intermediate steps don't have to be named. The example below has no `FROM` clause. Tables only need to be named if they will be joined downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>max_val:long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: col1:str,max_val:long</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql\n",
    "LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "SELECT col1, MAX(col2) AS max_val\n",
    " GROUP BY col1\n",
    " PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PRINT` keyword we used earlier actually uses anonymity. The fully written version would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>col2:long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: col1:str,col2:long</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql\n",
    "df = LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "PRINT 2 ROWS FROM df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking Python Code\n",
    "\n",
    "In all data computing frameworks, SQL is a second-class citizen often sandwiched between Python code. FugueSQL elevates SQL to be a first-class interface that can invoke Python code. We'll show an example below, but for more details about what functions can be used, see the [Fugue in 10 minutes](ten_minutes.ipynb) section. The valid functions for Fugue's `transform()` function will be the same as the ones in FugueSQL.\n",
    "\n",
    "Using Python can often reduce the amount of code that we need to write. For example, let's normalize the column like we did previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema: *+col2:float\n",
    "def std_dev(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.assign(col2=df['col2']/df['col2'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above is defined to handle one group of data at a time. In order to apply it per group, we partition the DataFrame first by group using the `PREPARTITION` and `TRANSFORM` keywords of FugueSQL. This semantic is similar to a `groupby-apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>col2:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: col1:str,col2:float</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql\n",
    "df = LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "TRANSFORM df PREPARTITION BY col1 USING std_dev\n",
    "PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Engine\n",
    "\n",
    "The strongest feature of FugueSQL is that it can be run on any of the backend engines Fugue supports. Fugue supports Pandas, Spark, Dask, and DuckDB. For operations on a laptop or single machine, DuckDB may give significant improvements over Pandas because it has a query optimizer. \n",
    "\n",
    "For data that is too large to process on a single machine, Spark or Dask can be used. All we need to do is specify the engine in the cell. For example, to run on DuckDB we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>col2:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: col1:str,col2:float</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql duckdb\n",
    "df = LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "TRANSFORM df PREPARTITION BY col1 USING std_dev\n",
    "PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to run on Spark, we can specify `%%fsql spark`. If there is a `SparkSession` defined, it will use it. Otherwise, it will start a new `SparkSession`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fugue.spark.use_pandas_udf is enabled but the current PySpark sessiondid not enable Pandas UDF support\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>col2:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">SparkDataFrame: col1:str,col2:float</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql spark\n",
    "df = LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "TRANSFORM df PREPARTITION BY col1 USING std_dev\n",
    "PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For production runs, we can specify the engine in the `.run()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fugue.spark.use_pandas_udf is enabled but the current PySpark sessiondid not enable Pandas UDF support\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>col2:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">SparkDataFrame: col1:str,col2:float</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"/tmp/df.parquet\")\n",
    "\n",
    "fsql(\"\"\"\n",
    "SELECT *\n",
    "  FROM df\n",
    " WHERE col1 = 'A' \n",
    "\n",
    "TRANSFORM PREPARTITION BY col1 USING std_dev\n",
    "PRINT\n",
    "\"\"\").run(\"spark\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FugueSQL in Scripts\n",
    "\n",
    "The `%%fsql` cell magic is meant for iteration inside Jupyter notebooks. To use FugueSQL in scripts, there is a `fugue_sql_flow` class that can be used. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1:str</th>\n",
       "      <th>max_val:long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">SparkDataFrame: col1:str,max_val:long</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fugue.api import fugue_sql_flow\n",
    "\n",
    "fugue_sql_flow(\"\"\"\n",
    "LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "SELECT col1, MAX(col2) AS max_val\n",
    " GROUP BY col1\n",
    " PRINT\n",
    "\"\"\").run(engine=\"spark\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the query only has a single return, users can use `fugue_sql` instead. This will just grab the last DataFrame of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>max_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  max_val\n",
       "0    A        3\n",
       "1    B        6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fugue.api import fugue_sql \n",
    "\n",
    "result = fugue_sql(\"\"\"\n",
    "LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "SELECT col1, MAX(col2) AS max_val\n",
    " GROUP BY col1\n",
    "\"\"\", engine=None)\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Computing Commands (Advanced)\n",
    "\n",
    "One of the weak points of SQL is that it doesn't have the grammar to describe distributed computing operations. For example, it's common to `PERSIST` DataFrames in Spark to hold them in memory so that they don't get recomputed.\n",
    "\n",
    "FugueSQL adds keywords such as `PERSIST` and `BROADCAST` to allow users to perform these operations without leaving SQL. In the example below, `df2` will not be recomputed on the Spark and Dask engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt:long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">SparkDataFrame: cnt:long</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql spark\n",
    "df = LOAD \"/tmp/df.parquet\"\n",
    "\n",
    "df2 = SELECT *\n",
    "        FROM df \n",
    "       WHERE col2 > 2\n",
    "     PERSIST\n",
    "\n",
    "SAVE df2 OVERWRITE \"/tmp/df-processed.parquet\"\n",
    "\n",
    "SELECT COUNT(col2) AS cnt\n",
    "  FROM df2\n",
    " PRINT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For a more detailed guide to FugueSQL, check the [FugueSQL section](../fugue_sql/index.md) of the documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9fcd6e71927f6b3e5f4fa4280b4e8e6a66aa8d4365bb61cf7ef4017620fc09b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
