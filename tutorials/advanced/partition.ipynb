{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Partitioning\n",
    "\n",
    "It's one of the most important concepts in Fugue. And it is slightly different from Spark's partition concept, so be careful. And this is also the most difficult Fugue concept to understand. We will go through a couple of examples, then go through the theory\n",
    "\n",
    "\n",
    "## Visualizing Partitions\n",
    "\n",
    "Assume we have a collection of colored balls with letters, they are stored in 5 buckets (gray bars).\n",
    "\n",
    "![](../../images/p_orig.svg)\n",
    "\n",
    "Now we are going to repartition these balls in different ways\n",
    "\n",
    "### Hash Partition: num=4\n",
    "Hash partition means we calculate a hash code according to the color and letter and put into the correspondent bucket. `num=4` means we want to use only bucket 0 1 2 3, and bucket 4 will be empty\n",
    "\n",
    "![](../../images/p_num_4.svg)\n",
    "\n",
    "### Rand Partition: num=4\n",
    "Rand partition means we assign a random code to a ball and put into the correspondent bucket. It's like reshuffle. The number of balls in each bucket should be similar, but not perfectly even. As you can see the following bucket 0 has 2 more balls than others.\n",
    "\n",
    "![](../../images/p_rand_num_4.svg)\n",
    "\n",
    "### Even Partition: num=4\n",
    "Now I want to enforce evenness. So, I use even partition, it guarantees the biggest and smallest buckets have at most 1 ball difference.\n",
    "\n",
    "![](../../images/p_even_num_4.svg)\n",
    "\n",
    "### Hash Partition: by color\n",
    "Now instead of giving a number, I specify partitioning by color. Each ball is assigned with a hash code by color. A main difference between Fugue and Spark is that, after partitioning by color, in each bucket, the balls are also sorted by color.\n",
    "\n",
    "Ans after sorting, we will see same colors are in chunks, we call each chunk a **logical partition**\n",
    "\n",
    "![](../../images/p_by_color_fugue.svg)\n",
    "\n",
    "#### (Spark) Hash Partition: by color\n",
    "In Spark, after partitioning by color, the balls in each bucket are not sorted.\n",
    "\n",
    "![](../../images/p_by_color_spark.svg)\n",
    "\n",
    "### Hash Partition: by color, presort letter\n",
    "In addition to partitioning, we also want to sort by letter. In Fugue, after partition-by, a sort will always happen, so when you specify a `presort`, it's just adding a key for the sort, so it doesn't add much overhead to the process. With presort, it's even faster than pandas udf in certain cases. (Fugue also [supports pandas udf](useful_config.ipynb#Use-Pandas-UDF-on-SparkExecutionEngine))\n",
    "\n",
    "![](../../images/p_by_color_presort.svg)\n",
    "\n",
    "### Rand Partition: by color\n",
    "In Fugue, there is no rand partition by color, it will become a hash partition by color\n",
    "\n",
    "![](../../images/p_by_color_fugue.svg)\n",
    "\n",
    "### Even Partition: by color\n",
    "Hash partition by color can't guarantee a single bucket contains a single color of balls. Even partition by color can guarantee that.\n",
    "\n",
    "![](../../images/p_even_by_color.svg)\n",
    "\n",
    "### Even Partition: by color, num=4\n",
    "When you also specify a number in even partition by, it guarantees `max(colors in a bucket)-min(colors in a bucket)<=1`. When you have more than tens of thousands of colors, you should consider using `num`\n",
    "\n",
    "![](../../images/p_even_num_4_by_color.svg)\n",
    "\n",
    "\n",
    "\n",
    "## Theory\n",
    "We will use the examples above the explain the theories.\n",
    "\n",
    "### Physical vs Logical Partitions\n",
    "\n",
    "One **physical** partition (one bucket in the above examples) is a subset of data that will be moved onto one machine and be processed by one worker thread. Notice one worker thread can still process multiple physical partitions, but one physical partition can only be processed by one thread (unless the process failed, and it may retry on another worker thread on another machine). Notice in one worker thread, the code can still use multi-thread, it's two different concepts.\n",
    "\n",
    "One **logical** partition (same color balls, after sort, in one bucket) is always inside one **physical** partition. One physical partition can contain multiple logical partitions, but one logical partition will guarantee to appear in only one physical partition. When logical partition is not defined, we use the physical partition as the logical partition.\n",
    "\n",
    "Fugue mainly focuses on the **logical** partition level, but you can also have custom handlers on **physical** level. For example, if it's to process every logical partition, you need the same expensive initialization, then you can move this to the physical level handler, which can save significant amount of time. (`on_init` in [this example](transformer.ipynb#Interface-Approach)\n",
    "\n",
    "There are 4 major components of the partition concept in Fugue.\n",
    "\n",
    "\n",
    "## Number Of Partitions\n",
    "\n",
    "It specifies **at most** how many **physical** partitions (buckets) for all rows.\n",
    "\n",
    "If you only specify number of partitions, it indicates you want to `reshuffle` the data to number of partitions so in the next step you can process them with controlled concurrency. Notice that Spark has more granular concepts, `repartition` and `coalesce`, you can read [this great article](https://blog.knoldus.com/apache-spark-repartitioning-v-s-coalesce/) for details.\n",
    "\n",
    "In current Fugue SparkExecutionEngine, we only use `repartition` because we notice that `reshuffle` is no longer bad in Spark. It performs extremely well in most cases, and data with `reshuffle` is a lot more balanced than `coalesce` without noticeable overhead. The advantage of `repartition` has been proven with numerous production use cases. Plus `coalesce` seems to be more inclined to `push-down`, causing a lot of hard-to-find performance issues. To avoid confusion and inconsistency, we only use `repartition` in SparkExecutionEngine. You can inherit from built-in SparkExecutionEngine and change to use `coalesce` if you feel that is useful to you.\n",
    "\n",
    "**All Fugue ExecutionEngine follows this rule of number of partitions**:\n",
    "* **<=0** means I don't want to repartition to current dataframe with an explicit number. The ExecutionEngine can decide whether to do nothing or reshuffle to new buckets.\n",
    "* **==1** means I want all data to move to a single physical partition\n",
    "* **>1** means I want to reshuffle the data to the number of physical partitions\n",
    "\n",
    "The underlying computing frameworks may have inconsistent behaviors on this (you have to be careful if moving away from Fugue), but on Fugue ExecutionEngine level, they are always consistent.\n",
    "\n",
    "\n",
    "## Partition Keys\n",
    "\n",
    "It specifies the keys to partition on. It is to define the **logical** partitions. All items with a same set of keys will be moved to a single physical location to process and partition keys is to tell the framework within this physical partition, I will separate the data by certain keys and process them separately.\n",
    "\n",
    "\n",
    "## Presort\n",
    "\n",
    "In each **physical** partition, to figure out the **logical** partitions, Fugue will sort first. And after you get the **logical** partitions, you may also need to sort inside that partition on some other keys before process.  By specifying `presort` you only add additional keys to the first sort. `presort` must not overlap with `partition keys`, and you can also specify whether to sort ascending or descending.\n",
    "\n",
    "Using [pandas udf on SparkExecutionEngine](useful_config.ipynb#Use-Pandas-UDF-on-SparkExecutionEngine) is an exception, the engine does not sort on physical partition, and presort step will happen inside each logical partition. The outcome is the same.\n",
    "\n",
    "\n",
    "## Partition Algorithms (Hint)\n",
    "\n",
    "Notice this is a hint, it does not require every ExecutionEngine to strictly follow. Currently only SparkExecutionEngine supports it. It has no effect on other engines.\n",
    "\n",
    "Currently 3 algos are supported: `HASH` (default), `RAND`, `EVEN`.\n",
    "\n",
    "No algo is good for everything, you need to use accordingly. The examples above have explained their differences. Here is a summary of pros and cons of each algo\n",
    "\n",
    "\n",
    "| . | `HASH` | `RAND` | `EVEN` |\n",
    "| --- | --- | --- | --- |\n",
    "| Speed | fast (map, shuffle) | fast (map, shuffle) | slow (map, reduce, map, shuffle) |\n",
    "| Space | low | low | high (need cache the dataframe first) |\n",
    "| Deterministic | yes | no | yes |\n",
    "| Eveness (small data) | bad | random | perfect (strict eveness) |\n",
    "| Eveness (big data) | good | good | perfect (but worth it?) |\n",
    "\n",
    "For large number of rows or for large number of partitions (when partition by keys is used), both `HASH` and `RAND` will generate even partitions, you may not need `EVEN`. But for small dataframe where each row/partition is expensive to process, `EVEN` will guarantee the perfect load balance.\n",
    "\n",
    "For example, you have a dataframe with 100 rows, it takes 1 hour to process each row, and you have 100 cores, if using `HASH` or `RAND` partition, you may get physical partitions with more than 1 row, for example you get 99 partitions, only 1 partition cotains 2 rows, but the whole process will still take 2 hours. But using `EVEN` you can reduce it to 1 hour.\n",
    "\n",
    "`EVEN` is the best for small size but expensive computations.\n",
    "\n",
    "\n",
    "## PartitionSpec in Fugue\n",
    "\n",
    "Here are examples to initialize PartitionSpec in Fugue. It's a widely used data structure"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from fugue import PartitionSpec\n",
    "\n",
    "assert PartitionSpec().empty # empty partition spec means no operation needed, it can be the default value\n",
    "PartitionSpec(num=4)\n",
    "PartitionSpec(algo=\"even\",num=4,by=[\"a\",\"b\"],presort=\"c,d desc\") # c,d desc == c asc, d desc\n",
    "\n",
    "# you can use expression in num, ROWCOUNT can be used to indicate using the row count of the dataframe to operate on\n",
    "# if a df has 1000 rows, this means I want to even partition it to 10 rows per partition\n",
    "PartitionSpec(algo=\"even\",num=\"ROWCOUNT/10\") "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PartitionSpec(num='ROWCOUNT/10', by=[], presort='')"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}